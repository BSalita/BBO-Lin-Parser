{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7be58cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:04:05.683157Z",
     "start_time": "2023-09-18T21:04:05.679796Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:04:19.060409Z",
     "iopub.status.busy": "2024-02-12T04:04:19.060409Z",
     "iopub.status.idle": "2024-02-12T04:04:19.067099Z",
     "shell.execute_reply": "2024-02-12T04:04:19.066093Z",
     "shell.execute_reply.started": "2024-02-12T04:04:19.060409Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 30m to 10h for 10m files. Highly variable depending on caching of lin files.\n",
    "# not working in jupyterlab but ok in vscode?\n",
    "# be sure to pip install -U -r requirements.txt # in particular xlsxwriter must be installed otherwise there may be a silent failure.\n",
    "# requires 150gb of memory.\n",
    "\n",
    "# requires outputs to be cleared before posting to github due to 250MB size.\n",
    "# if git fails due to large size, rollback one git commit using: git reset --soft HEAD~1\n",
    "\n",
    "# reads and parses BBO .lin files. Lin files are a record of bids and card plays for a single board and single table of a BBO online match.\n",
    "# use BBO-DownLoader to download *.lin files\n",
    "# parses all *.lin files in a directory.\n",
    "# outputs a .py file of one tuple per per bidding sequences (id,previous bids,candidate bid, announcement, pandas eval expr).\n",
    "\n",
    "# next steps:\n",
    "# acbl_club_results_hand_records_bidding_BBO.ipynb augments hand records with BBO bidding sequences.\n",
    "\n",
    "# previous steps:\n",
    "# BBO-Downloader.py downloads BBO's .lin files based on date range.\n",
    "\n",
    "# todo:\n",
    "# make Parse_BBO_Lin_File() return values for dealer, hands, vul\n",
    "# validate bidding sequences for consistency in criteria e.g. HCP, overlap with other bids. Produce coverage heat maps.\n",
    "# chart player vs field\n",
    "# process error_files to understand disconnect/withdrawl rates of players.\n",
    "# double check each bids criteria by comparing to actual use. create mean and stdev (BBO's HCP, SL, QT, ...) for each bid.\n",
    "#    ... See which bids fall outside criteria or are missing crucial criteria. e.g. 4N opener.\n",
    "# Compare bidding sequences to actual PAR/SD looking for bad result outliers. Use info to correct or optimize bids.\n",
    "# get additional info from tourney*.html (.3%), traveler*.html (3%) (*.lin 97%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f52011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:04:06.171147Z",
     "start_time": "2023-09-18T21:04:05.684159Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:04:19.594302Z",
     "iopub.status.busy": "2024-02-12T04:04:19.593234Z",
     "iopub.status.idle": "2024-02-12T04:04:20.378813Z",
     "shell.execute_reply": "2024-02-12T04:04:20.378813Z",
     "shell.execute_reply.started": "2024-02-12T04:04:19.594302Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from IPython.display import display # needed to define display() method in vscode\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "#!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0603ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:04:06.174687Z",
     "start_time": "2023-09-18T21:04:06.172149Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:04:20.381812Z",
     "iopub.status.busy": "2024-02-12T04:04:20.381267Z",
     "iopub.status.idle": "2024-02-12T04:04:20.387221Z",
     "shell.execute_reply": "2024-02-12T04:04:20.386136Z",
     "shell.execute_reply.started": "2024-02-12T04:04:20.381812Z"
    }
   },
   "outputs": [],
   "source": [
    "rootPath = pathlib.Path('e:/bridge/data')\n",
    "bboPath = rootPath.joinpath('bbo')\n",
    "dataPath = bboPath.joinpath('data')\n",
    "# create parent directories in case they don't already exist.\n",
    "dataPath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd89b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:04:41.585633Z",
     "start_time": "2023-09-18T21:04:06.175448Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:04:21.010119Z",
     "iopub.status.busy": "2024-02-12T04:04:21.009118Z",
     "iopub.status.idle": "2024-02-12T04:05:13.898544Z",
     "shell.execute_reply": "2024-02-12T04:05:13.897537Z",
     "shell.execute_reply.started": "2024-02-12T04:04:21.010119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9898008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# takes 1m\n",
    "lin_wildcard = '*/*.lin'\n",
    "lin_files = list(dataPath.glob(lin_wildcard))\n",
    "len(lin_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a92399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:04:41.601518Z",
     "start_time": "2023-09-18T21:04:41.586748Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:05:13.899542Z",
     "iopub.status.busy": "2024-02-12T04:05:13.899542Z",
     "iopub.status.idle": "2024-02-12T04:05:13.924858Z",
     "shell.execute_reply": "2024-02-12T04:05:13.923848Z",
     "shell.execute_reply.started": "2024-02-12T04:05:13.899542Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse bbo lin files.\n",
    "# todo: return values for dealer, hands, vul\n",
    "\n",
    "# using walrus operator (:=) so must use python >= 3.8\n",
    "\n",
    "# todo: implement vulnerability. bids may differ according to vulnerability.\n",
    "\n",
    "# Lin files are often malformed because of disconnects or withdrawls\n",
    "\n",
    "def Parse_BBO_Lin_File(lin):\n",
    "    bids = None\n",
    "    board = None\n",
    "    cards = None\n",
    "    dealer = None\n",
    "    hands = None\n",
    "    username = None\n",
    "    vul = None\n",
    "    i = 0\n",
    "    #print(f\"{lin=}\")\n",
    "    if not lin.startswith('pn'):\n",
    "        print('Player name marker missing')\n",
    "        return i, username, board, dealer, vul, hands, bids, cards\n",
    "    parts = lin.replace('\\n','').split('|')\n",
    "    #print(f\"{parts=}\")\n",
    "    i = 0\n",
    "    if i >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i]=='pn', parts[i] # player marker\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    players = parts[i].split(',')\n",
    "    assert len(players) == 4, parts[i]\n",
    "    username = players[0] # should robotnames (players[1:]) be discarded?\n",
    "    #print(f\"{username=} {players}\")\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == 'st', parts[i] # start?\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == '', parts[i] # expecting empy\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == 'md', parts[i] # hands\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    dealer = parts[i][0] # 1=south, 2=west, 3=north, 4=east\n",
    "    assert dealer in '1234', dealer\n",
    "    hands = parts[i][1:].split(',') # 4th hand is '' to minimize BBO's disk space\n",
    "    assert len(hands) == 4, parts[i]\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == 'rh' # unknown\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == '' # expecting empty\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == 'ah', parts[i]\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    board_parts = parts[i].split(' ')\n",
    "    assert len(board_parts) == 2 and board_parts[0] == 'Board', parts[1]\n",
    "    board = board_parts[1]\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == 'sv', parts[i] # unknown\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    vul = parts[i] # o=none, n=north-south, e=east-west, b=both\n",
    "    assert vul in 'oneb', vul\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    if len(parts) < i+2:\n",
    "        return i, username, board, dealer, vul, hands, bids, cards\n",
    "    bids = []\n",
    "    passes = 0\n",
    "    while parts[i] == 'mb': # make bid\n",
    "        #print(f\"1: {parts[i]=}\")\n",
    "        if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "        bid = parts[i]\n",
    "        #print(f\"2: {parts[i]=}\")\n",
    "        announcement = ''\n",
    "        if bid == 'p' or bid == 'p!':\n",
    "            passes += 1\n",
    "        else:\n",
    "            passes = 0\n",
    "        if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "        #print(f\"3: {parts[i]=}\")\n",
    "        # rarely there's an unannounced bid e.g 1C in 3268628079-1676148841-linkay01.lin\n",
    "        if parts[i] == 'an': # announcement\n",
    "            if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "            announcement = parts[i]\n",
    "            assert isinstance(announcement,str), announcement\n",
    "            announcement = str(announcement).strip() # could have leading/trailing spaces or be mistaken for numeric type\n",
    "            #print(f\"5: {parts[i]=} {i} {len(parts)}\")\n",
    "            if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "        #print(f\"6: {parts[i]=} {i} {len(parts)}\")\n",
    "        if parts[i] != 'mb' and parts[i] != 'pg':\n",
    "            return i, username, board, dealer, vul, hands, bids, cards\n",
    "        bids.append((bid, announcement))\n",
    "    if passes == 4:\n",
    "        assert len(bids) == 4\n",
    "        return i, username, board, dealer, vul, hands, bids, cards # passed out so it's ok that no cards are played\n",
    "    assert passes == 3 and len(bids) > 3, f\"{passes=} {len(bids)=} {bids=}\"\n",
    "    #print(f\"{bids=}\")\n",
    "    cards = {}\n",
    "    for trick in range(13):\n",
    "        assert parts[i] == 'pg', parts[i] # play card\n",
    "        if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "        if parts[i] == 'mc': # member claimed\n",
    "            return -2, username, board, dealer, vul, hands, bids, cards\n",
    "        assert parts[i] == '' # expecting empty\n",
    "        if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "        trick += 1\n",
    "        for pcn in range(4):\n",
    "            if parts[i] == 'mc': # member claimed\n",
    "                return -2, username, board, dealer, vul, hands, bids, cards\n",
    "            if parts[i] != 'pc': # malformed\n",
    "                return i, username, board, dealer, vul, hands, bids, cards\n",
    "            if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "            card = parts[i] # todo: parse card to validate\n",
    "            if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "            assert card not in cards\n",
    "            pcn += 1\n",
    "            cards[card] = (card, trick, pcn)\n",
    "    #print(f\"{cards}\")\n",
    "    assert len(cards) == 52, len(cards) # todo: show which cards are missing\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == ''\n",
    "    if (i := i+1) >= len(parts): return i, username, board, dealer, vul, hands, bids, cards\n",
    "    assert parts[i] == ''\n",
    "    assert i+1 == len(parts), [i,len(parts)]\n",
    "    return -1, username, board, dealer, vul, hands, bids, cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b22e2f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:13:21.594429Z",
     "start_time": "2023-09-18T21:04:41.602028Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:05:13.925857Z",
     "iopub.status.busy": "2024-02-12T04:05:13.925857Z",
     "iopub.status.idle": "2024-02-12T04:38:00.234124Z",
     "shell.execute_reply": "2024-02-12T04:38:00.233120Z",
     "shell.execute_reply.started": "2024-02-12T04:05:13.925857Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 20m to 35m\n",
    "# previously parsed lin files are cached in bbo_parsed_lin_files. use it if exists.\n",
    "bbo_parsed_lin_files_filename = 'bbo_parsed_lin_files.pkl'\n",
    "bbo_parsed_lin_files_file = dataPath.joinpath(bbo_parsed_lin_files_filename)\n",
    "if bbo_parsed_lin_files_file.exists():\n",
    "    with open(bbo_parsed_lin_files_file, 'rb') as f:\n",
    "        files_processed, bidding_table, error_files, bid_table, final_contracts, announcements = pickle.load(f)\n",
    "else:\n",
    "    files_processed = {} # initialize here for re-runing\n",
    "    bidding_table = {} # (previous bids, current bid, announcement)\n",
    "    error_files = {} # invalid files\n",
    "    bid_table = {} # individual bids\n",
    "    final_contracts = {} # final contract\n",
    "    announcements = defaultdict(list) # announcements (alerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a01085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:17:53.150988Z",
     "start_time": "2023-09-18T21:13:21.594429Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 30m or 4h or 9h depending on bbo_parsed_lin_files and file caching. 5m files (150000 files per minute).\n",
    "# Read a glob of lin files, parse, create various dicts (bids, errors, final contracts, announcements).\n",
    "\n",
    "# todo: switch to defaultdict\n",
    "\n",
    "# Make4thHand adds the missing 4th hand which isn't present to minimize BBO's disk space. adds < 1m\n",
    "def Make4thHand(hands):\n",
    "    #print(hands)\n",
    "    if hands is not None:\n",
    "        #hands[3] = ''\n",
    "        assert len(hands) == 4 and all(len(h)==13+4 for h in hands[0:3]) and hands[3] == '', hands\n",
    "        suits = ['']*4\n",
    "        for h in hands[0:3]:\n",
    "            mg = re.match(r'^S(.*)H(.*)D(.*)C(.*)$',h)\n",
    "            assert mg is not None, mg\n",
    "            for i,cards in enumerate(mg.groups(0)):\n",
    "                #print(i,cards)\n",
    "                suits[i] += cards\n",
    "        #print(suits)\n",
    "        #hands[3] = ''.join(['SHDC'[i]+''.join(set(list('23456789TJQKA'))-set(list(suits[i]))) for i,s in enumerate(suits)])\n",
    "        for i,suit in enumerate('SHDC'):\n",
    "            hands[3] += suit\n",
    "            for c in '23456789TJQKA':\n",
    "                #print(c,suits[i])\n",
    "                if c not in suits[i]:\n",
    "                    hands[3] += c\n",
    "        #print(hands[3])\n",
    "        assert len(hands[3]) == 13+4,hands[3]\n",
    "    return hands\n",
    "\n",
    "for i,lin_file in enumerate(lin_files):\n",
    "    #print(f\"\\n{i}/{len(lin_files)}: Reading:{lin_file.name}\",end='')\n",
    "    if lin_file in files_processed:\n",
    "        error, username, board, dealer, vul, hands, bids, cards = files_processed[lin_file]\n",
    "    else:\n",
    "        with open(lin_file, 'r', encoding='utf8') as f:\n",
    "            lin = f.read()\n",
    "        #print(f\" len:{len(lin)}\",end='')\n",
    "        #if (i % 200) == 0: time.sleep(.1) # needed in jupyter notebook to slow down output\n",
    "        Parse_BBO_Lin_File(lin)\n",
    "        error, username, board, dealer, vul, hands, bids, cards = Parse_BBO_Lin_File(lin)\n",
    "        files_processed[lin_file] = (error, username, board, dealer, vul, Make4thHand(hands), bids, cards)\n",
    "    if error == -1:\n",
    "        #print(f\" Played out. {username=}\",end='') # {bids=} {cards=}\")\n",
    "        pass\n",
    "    elif error == -2:\n",
    "        #print(f\" Successful claim. {username=}\",end='') # {bids=} {cards=}\")\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"{i}/{len(lin_files)}: Invalid file (disconnect or withdrawn). {error=}\")\n",
    "        if username is not None:\n",
    "            if username not in error_files:\n",
    "                error_files[username] = []\n",
    "            error_files[username].append(lin_file)\n",
    "        continue\n",
    "        \n",
    "    # iterate through hand's bidding history\n",
    "    prev_bids = [] # previous bids\n",
    "    last_bid = None # last bid made\n",
    "    for bid, announcement in bids:\n",
    "        #print(f\"\\n{prev_bids=} {bid=} {announcement=}\")\n",
    "        prev_bid = (tuple(prev_bids),(bid,))\n",
    "        assert isinstance(prev_bid,tuple) and isinstance(prev_bid[0],tuple) and isinstance(prev_bid[1],tuple), prev_bid\n",
    "        if prev_bid not in bidding_table:\n",
    "            bidding_table[prev_bid] = []\n",
    "        bidding_table[prev_bid].append((announcement,lin_file))\n",
    "        prev_bids.append(bid)\n",
    "        announcements[announcement].append((prev_bids,bid,lin_file))\n",
    "    # validate some more. make some handy collections.\n",
    "    passes = 0 # number of consecutive passes\n",
    "    d = False # double\n",
    "    r = False # redouble\n",
    "    last_bid = None\n",
    "    for bid in prev_bids:\n",
    "        if bid == 'p' or bid == 'p!':\n",
    "            passes += 1\n",
    "            assert passes < 4 or (passes == 4 and len(prev_bids) == 4)\n",
    "        else:\n",
    "            assert passes < 3 or (passes == 3 and len(prev_bids) >= 4)\n",
    "            passes = 0\n",
    "            if bid[0] == 'd': # could be d or d!\n",
    "                assert last_bid is not None\n",
    "                assert not d and not r\n",
    "                d = True\n",
    "                r = False\n",
    "            elif bid[0] == 'r': # could be r or r!\n",
    "                assert last_bid is not None\n",
    "                assert d and not r\n",
    "                d = False\n",
    "                r = True\n",
    "            else: # all others\n",
    "                last_bid = bid\n",
    "                d = False\n",
    "                r = False\n",
    "                if last_bid not in bid_table:\n",
    "                    bid_table[last_bid] = []\n",
    "                bid_table[last_bid].append((d,r,lin_file))\n",
    "    assert passes == 3 or (passes == 4 and len(prev_bids) == 4)\n",
    "    assert passes == 4 or last_bid is not None\n",
    "    if last_bid not in final_contracts:\n",
    "        final_contracts[last_bid] = []\n",
    "    final_contracts[last_bid].append((d,r,lin_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f277d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:18:18.740340Z",
     "start_time": "2023-09-18T21:17:53.151990Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 25s\n",
    "len(bidding_table), bidding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c98eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:27:41.879261Z",
     "start_time": "2023-09-18T21:18:18.740340Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 10m\n",
    "bbo_parsed_lin_files_filename = 'bbo_parsed_lin_files.pkl'\n",
    "bbo_parsed_lin_files_file = dataPath.joinpath(bbo_parsed_lin_files_filename)\n",
    "with open(bbo_parsed_lin_files_file, 'wb') as f:\n",
    "    pickle.dump([files_processed, bidding_table, error_files, bid_table, final_contracts, announcements],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de99b0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:27:41.907935Z",
     "start_time": "2023-09-18T21:27:41.895134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314739\n"
     ]
    }
   ],
   "source": [
    "print(len(announcements))\n",
    "if False: # disabled because takes 10+m\n",
    "    for k,v in sorted(announcements.items()):\n",
    "        print(f'\"{k}\" {len(v)}')\n",
    "        time.sleep(.0001) # slow down output to avoid \"too much, too fast\" warning\n",
    "        assert isinstance(k,str), k\n",
    "        assert '\"' not in k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e9e61d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:27.003854Z",
     "start_time": "2023-09-18T21:27:41.907935Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T04:38:00.236428Z",
     "iopub.status.busy": "2024-02-12T04:38:00.235425Z",
     "iopub.status.idle": "2024-02-12T05:01:22.002148Z",
     "shell.execute_reply": "2024-02-12T05:01:22.002148Z",
     "shell.execute_reply.started": "2024-02-12T04:38:00.236428Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 24m for 10m sequences\n",
    "# creates corrected bidding and announcements tables. Remove wrong/obsolete announcements keeping one and only one.\n",
    "# todo: fix legacy filename\n",
    "\n",
    "corrected_bidding_table = {}\n",
    "corrected_announcements = defaultdict(list)\n",
    "obsolete_announcements = {} # bids which have been obsoleted by corrected bids\n",
    "with open('announcement_conflicts.txt','w',encoding='utf8') as f:\n",
    "    date_time_str = datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    f.write('\\n')\n",
    "    f.write(f\"List of conflicting annnouncements. Automatically created on {date_time_str} by bbo_parse_lin_files.ipynb.\\n\")\n",
    "    f.write('\\n')\n",
    "    for i,(k,v) in enumerate(bidding_table.items()):\n",
    "        #print(i,k,v)\n",
    "        # escape special characters\n",
    "        #sorted_announcements = sorted((lin_file,an) for an,lin_file in v) # keep newest announcement per id in filename. Could use epoch instead.\n",
    "        #keeper_lin_file, keeper_an = sorted_announcements[-1]\n",
    "        sorted_announcements = sorted((len(an),an,lin_file) for an,lin_file in v) # keep longest announcement per id in filename. Could use epoch instead.\n",
    "        keeper_an_len, keeper_an, keeper_lin_file = sorted_announcements[-1]\n",
    "        corrected_announcements[keeper_an].append(keeper_lin_file)\n",
    "        corrected_bidding_table[k] = (keeper_an,keeper_lin_file)\n",
    "        for an_len,an,lin_file in sorted_announcements[:-1]:\n",
    "            #if an != keeper_an:\n",
    "            #    if len(an) > len(keeper_an):\n",
    "            #        print('length discrepency:',len(an),len(keeper_an))\n",
    "            if an != keeper_an and an not in obsolete_announcements: # capture only first instance of obs an\n",
    "                    print(f\"\\n{i}/{len(bidding_table)}: Conflicting announcements: bidding sequence: {' '.join(k[0])} {k[1][0]}?\")\n",
    "                    f.write(f\"\\n{i}/{len(bidding_table)}: Conflicting announcements: bidding sequence: {' '.join(k[0])} {k[1][0]}?\\n\")\n",
    "                    print(f\"   Keeping:'{keeper_an}' file:{keeper_lin_file.name}\")\n",
    "                    f.write(f\"   Keeping:'{keeper_an}' file:{keeper_lin_file.name}\\n\")\n",
    "                    print(f\"  Obsolete:'{an}' file:{lin_file.name}\")\n",
    "                    f.write(f\"  Obsolete:'{an}' file:{lin_file.name}\\n\")\n",
    "                    obsolete_announcements[an] = (an,lin_file,keeper_an,keeper_lin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373621c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:27.008577Z",
     "start_time": "2023-09-18T21:36:27.004857Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:22.004154Z",
     "iopub.status.busy": "2024-02-12T05:01:22.004154Z",
     "iopub.status.idle": "2024-02-12T05:01:22.009912Z",
     "shell.execute_reply": "2024-02-12T05:01:22.008906Z",
     "shell.execute_reply.started": "2024-02-12T05:01:22.004154Z"
    }
   },
   "outputs": [],
   "source": [
    "# dict of bidding table\n",
    "print(corrected_bidding_table[((),('1N',))])\n",
    "# dict of corrected announcements, key is corrected announcement, value is lin file containing correction\n",
    "print('\\n',corrected_announcements['notrump opener. Could have 5M. -- 2-5 !C; 2-5 !D; 2-5 !H; 2-5 !S; 15-17 HCP; 18- total points'])\n",
    "# dict of obsolete_announcements, key is obsolete announcement, value is (obs an,obs lin file, corrected an, corrected lin file).\n",
    "print('\\n',obsolete_announcements['notrump opener. Could have 5M. -- 2-5 !C; 2-5 !D; 2-5 !H; 2-5 !S; 15-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d9d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:27.135133Z",
     "start_time": "2023-09-18T21:36:27.009602Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:22.010913Z",
     "iopub.status.busy": "2024-02-12T05:01:22.010913Z",
     "iopub.status.idle": "2024-02-12T05:01:22.166605Z",
     "shell.execute_reply": "2024-02-12T05:01:22.166605Z",
     "shell.execute_reply.started": "2024-02-12T05:01:22.010913Z"
    }
   },
   "outputs": [],
   "source": [
    "corrected_bidding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cc10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:27.713579Z",
     "start_time": "2023-09-18T21:36:27.136136Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:22.168609Z",
     "iopub.status.busy": "2024-02-12T05:01:22.168609Z",
     "iopub.status.idle": "2024-02-12T05:01:23.418075Z",
     "shell.execute_reply": "2024-02-12T05:01:23.417068Z",
     "shell.execute_reply.started": "2024-02-12T05:01:22.168609Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrected_announcements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454bfdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:27.780919Z",
     "start_time": "2023-09-18T21:36:27.713579Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:23.419074Z",
     "iopub.status.busy": "2024-02-12T05:01:23.419074Z",
     "iopub.status.idle": "2024-02-12T05:01:23.443240Z",
     "shell.execute_reply": "2024-02-12T05:01:23.443240Z",
     "shell.execute_reply.started": "2024-02-12T05:01:23.419074Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(obsolete_announcements,orient='index',columns=['Obsolete Announcement','Obsolete Lin File','Corrected Announcement','Corrected Lin File'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e718e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:28.985878Z",
     "start_time": "2023-09-18T21:36:27.780919Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:23.445246Z",
     "iopub.status.busy": "2024-02-12T05:01:23.445246Z",
     "iopub.status.idle": "2024-02-12T05:01:26.450181Z",
     "shell.execute_reply": "2024-02-12T05:01:26.449177Z",
     "shell.execute_reply.started": "2024-02-12T05:01:23.445246Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 3s\n",
    "# attempt to find truncated announcements and replace with full description\n",
    "truncated_bids = {}\n",
    "for k in corrected_bidding_table.keys():\n",
    "    #print(k)\n",
    "    if (k[0],(k[1][0]+'!',)) in corrected_bidding_table:\n",
    "        print()\n",
    "        print('dup!')\n",
    "        k1 = k\n",
    "        b1 = corrected_bidding_table[k1][0]\n",
    "        k2 = (k[0],(k[1][0]+'!',))\n",
    "        b2 = corrected_bidding_table[k2][0]\n",
    "        if b1 == b2:\n",
    "            print('both announcements are same except for candidate bid:',b1)\n",
    "            if k1[0] != k2[0]:\n",
    "                print('also differ in previouis bids:',k1[0],k2[0])\n",
    "            continue\n",
    "        if len(b1) <= len(b2):\n",
    "            if b2.startswith(b1):\n",
    "                print('b1 is truncated:')\n",
    "                truncated_bids[k1] = corrected_bidding_table[k2]\n",
    "            else:\n",
    "                print('NOT truncated') \n",
    "            print(f\"b1: {b1} # {k1}\")\n",
    "            print(f\"b2: {b2} # {k2}\")\n",
    "        else:\n",
    "            if b1.startswith(b2):\n",
    "                print('b2 is truncated:')\n",
    "                truncated_bids[k2] = corrected_bidding_table[k1]\n",
    "            else:\n",
    "                print('NOT truncated') \n",
    "            print(f\"b2: {b2} # {k2}\")\n",
    "            print(f\"b1: {b1} # {k1}\")\n",
    "\n",
    "# attempt to fix truncated announcement so pandas eval expr will be correct\n",
    "for k,v in truncated_bids.items():\n",
    "    corrected_bidding_table[k] = v\n",
    "    corrected_announcements[v[0]] = v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03735c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:28.991025Z",
     "start_time": "2023-09-18T21:36:28.986880Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:26.453489Z",
     "iopub.status.busy": "2024-02-12T05:01:26.452492Z",
     "iopub.status.idle": "2024-02-12T05:01:26.458205Z",
     "shell.execute_reply": "2024-02-12T05:01:26.458205Z",
     "shell.execute_reply.started": "2024-02-12T05:01:26.453489Z"
    }
   },
   "outputs": [],
   "source": [
    "# interesting algorithm. given a list of possibly truncated words, return the list of non-truncated words.\n",
    "# unable to describe to chatgpt or bard. maybe it just can't do it.\n",
    "\n",
    "# function comments automatically generated by chatgpt from no-comment form. It can rename variables too.\n",
    "\n",
    "def create_list_of_non_trucations(expr_keywords, kw):\n",
    "    \"\"\"\n",
    "    Modifies a list of word and truncations. Discovers the word and discards any truncations.\n",
    "\n",
    "    Args:\n",
    "        expr_keywords (list): The list of existing words or expressions.\n",
    "        kw (str): The new word or expression to be added or checked for truncations.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the input list in-place by removing truncations or appending the new word.\n",
    "    \"\"\"\n",
    "    for k in expr_keywords.copy():  # Iterate over a copy of the expr_keywords list\n",
    "        if k.startswith(kw):  # If new word matches the start of another word in the list, no action needed\n",
    "            return  # Return to exit the function\n",
    "        if kw.startswith(k):  # If an existing word in the list matches the start of the new word\n",
    "            expr_keywords.remove(k)  # Remove the existing word from the list\n",
    "            expr_keywords.append(kw)  # Add the new word to the list\n",
    "            return  # Return to exit the function\n",
    "    expr_keywords.append(kw)  # Add the new word to the list if no truncation is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6940b97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:40.591549Z",
     "start_time": "2023-09-18T21:36:28.991533Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:26.460209Z",
     "iopub.status.busy": "2024-02-12T05:01:26.459209Z",
     "iopub.status.idle": "2024-02-12T05:01:57.069610Z",
     "shell.execute_reply": "2024-02-12T05:01:57.069081Z",
     "shell.execute_reply.started": "2024-02-12T05:01:26.460209Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 30s for 300,000 corrected announcements\n",
    "# must be case-insensitive\n",
    "\n",
    "sub_expr_parts = defaultdict(list)\n",
    "expr_keywords = []\n",
    "truncations =  []\n",
    "sub_expr_parts_list = []\n",
    "corrected_announcement_parts = {}\n",
    "\n",
    "print('corrected_announcements:',len(corrected_announcements))\n",
    "for i,an in enumerate(corrected_announcements):\n",
    "    print(f\"\\n{i}: {an=}\")\n",
    "    corrected_announcement_parts[an] = (None, None, None)\n",
    "    if an == '':\n",
    "        continue\n",
    "    an_parts = an.split('--')\n",
    "    if len(an_parts) == 1:\n",
    "        comment = None\n",
    "        expr_list = an_parts[0].strip()\n",
    "    elif len(an_parts) == 2:\n",
    "        comment = an_parts[0].strip()\n",
    "        expr_list = an_parts[1].strip()\n",
    "    else:\n",
    "        print('Invalid announcement:',an)\n",
    "        continue\n",
    "    print(f\"{comment=}\")\n",
    "    print(f\"{expr_list=}\")\n",
    "    expr_parts = expr_list.split(';') # expression delimiter. all expressions are logicals AND meaning they must all be True.\n",
    "    # some expressions contain a comma. That's probably a BBO bug. We're treating a ',' as a ';'\n",
    "    expr_parts = sum([e.split(',') for e in expr_parts],[]) # sum() will flatten a list of lists\n",
    "    corrected_announcement_parts[an] = (comment,expr_list,expr_parts)\n",
    "    for sub_expr in expr_parts:\n",
    "        print(f\"  {sub_expr=}\")\n",
    "        sub_expr_parts = sub_expr.split(' ')\n",
    "        if '' in sub_expr_parts: # todo: how does this happen?\n",
    "            sub_expr_parts.remove('')\n",
    "        sub_expr_parts_list.append((sub_expr_parts,an))\n",
    "        for se in sub_expr_parts:\n",
    "            sep = se.strip()\n",
    "            if sep == '':\n",
    "                continue\n",
    "            print(f\"   {sep=}\")\n",
    "            if str.isalpha(sep):\n",
    "                create_list_of_non_trucations(expr_keywords,sep)\n",
    "                if sep not in truncations:\n",
    "                    truncations.append(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a6770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:40.598993Z",
     "start_time": "2023-09-18T21:36:40.591549Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:01:57.071195Z",
     "iopub.status.busy": "2024-02-12T05:01:57.070664Z",
     "iopub.status.idle": "2024-02-12T05:01:57.085251Z",
     "shell.execute_reply": "2024-02-12T05:01:57.084728Z",
     "shell.execute_reply.started": "2024-02-12T05:01:57.071195Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(expr_keywords), sorted(truncations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb76e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T21:36:40.621213Z",
     "start_time": "2023-09-18T21:36:40.598993Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:15:39.559400Z",
     "iopub.status.busy": "2024-02-12T05:15:39.559029Z",
     "iopub.status.idle": "2024-02-12T05:15:39.585196Z",
     "shell.execute_reply": "2024-02-12T05:15:39.584186Z",
     "shell.execute_reply.started": "2024-02-12T05:15:39.559400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # initialize with special cases to prevent undesired substitution\n",
    "truncation_to_keywords = {\n",
    "    #'points':'', # prevent total without points\n",
    "    'st':'stop', # prevent st->strong as it seems to be mainly stop\n",
    "    'stop':'stop', # prevent stop->stops\n",
    "    'to':'to', # prevent to->total\n",
    "    #'total':'total points', # prevent total without points\n",
    "}\n",
    "\n",
    "def create_dict_of_trunctions(expr_keywords,truncations,truncation_to_keywords):\n",
    "    for t in truncations:\n",
    "        if t not in truncation_to_keywords:\n",
    "            for k in expr_keywords:\n",
    "                if k.startswith(t):\n",
    "                    break\n",
    "            truncation_to_keywords[t] = k\n",
    "        #assert False, f\"{t} not in {expr_keywords}\"\n",
    "        \n",
    "create_dict_of_trunctions(expr_keywords,truncations,truncation_to_keywords)\n",
    "sorted(truncation_to_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628caed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:30:20.580958Z",
     "start_time": "2023-09-18T22:29:55.348464Z"
    },
    "execution": {
     "iopub.execute_input": "2024-02-12T05:16:08.017371Z",
     "iopub.status.busy": "2024-02-12T05:16:08.017371Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# takes 20m or 300,000 bids/s\n",
    "# Convert bidding announcememts to Pandas compatible eval() expressions.\n",
    "# GIB jargon is well-suited for direct use by eval(). e.g. 12 <= HCP <= 21 & SL_H == 5 & Rebiddable==True\n",
    "\n",
    "# GIB bidding descriptions are defined per https://www.bridgebase.com/doc/gib_descriptions.php\n",
    "# GIB's HCP uses 4321 point count system\n",
    "# GIB's Total Points = HCP + (short-suit points (123)) + (-1 for each short suit with HCP)\n",
    "\n",
    "# RegEx notes:\n",
    "# all bids must match one and only one of these regex. Otherwise a new regex is needed.\n",
    "# GIB regex for suits: !([CDHS]) e.g. !C meaning club suit\n",
    "# GIB regex for bids: \\d[CDHSN] e.g. 1N meaning 1 no-trump\n",
    "\n",
    "# Target column naming:\n",
    "# SL_[CDHS] is suit length. e.g. SL_C is suit length of clubs\n",
    "# C_[CDHS][AKQJT98765432]+ designates specific cards in a suit e.g C_HAK means Heart suit must include both Ace and King.\n",
    "\n",
    "# todo: double check that all announcements without the words HCP or Total are implied HCP and not Total Points\n",
    "def HCP_Exact(regex,match): # 10\n",
    "    return f\"HCP == {match.group(1)}\"\n",
    "\n",
    "def HCP_At_Most(regex,match): # 10-\n",
    "    return f\"HCP <= {match.group(1)}\"\n",
    "\n",
    "def HCP_At_Least(regex,match): # 10+\n",
    "    return f\"HCP >= {match.group(1)}\"\n",
    "\n",
    "def HCP_Between(regex,match): # 10-12\n",
    "    return f\"{match.group(1)} <= HCP <= {match.group(2)}\"\n",
    "\n",
    "def Suit_Length_Exact(regex,match): # 4 !C\n",
    "    return f\"SL_{match.group(2)} == {match.group(1)}\"\n",
    "\n",
    "def Suit_Length_At_Most(regex,match): # 4- !C\n",
    "    return f\"SL_{match.group(2)} <= {match.group(1)}\"\n",
    "\n",
    "def Suit_Length_At_Least(regex,match): # 4+ !C\n",
    "    return f\"SL_{match.group(2)} >= {match.group(1)}\"\n",
    "\n",
    "def Suit_Length_Between(regex,match): # 2-3 !C\n",
    "    return f\"{match.group(1)} <= SL_{match.group(3)} <= {match.group(2)}\"\n",
    "\n",
    "# todo: Eliminate Total_Points replacing with HCP and DP?\n",
    "def Total_Points_Exact(regex,match): # 10 total points\n",
    "    return f\"Total_Points == {match.group(1)}\"\n",
    "\n",
    "def Total_Points_At_Most(regex,match): # 10- total points\n",
    "    return f\"Total_Points <= {match.group(1)}\"\n",
    "\n",
    "def Total_Points_At_Least(regex,match): # 10+ total points\n",
    "    return f\"Total_Points >= {match.group(1)}\"\n",
    "\n",
    "def Total_Points_Between(regex,match): # 10-12 total points\n",
    "    return f\"{match.group(1)} <= Total_Points <= {match.group(2)}\"\n",
    "\n",
    "def Cards_In_Suit(regex,match): # Q+ in !C\n",
    "    return ' & '.join('C_'+match.group(2)+c+'==True' for c in match.group(1))\n",
    "\n",
    "def Suit_Has_Cards(regex,match): # !CAK\n",
    "    return ' & '.join('C_'+match.group(1)+c+'==True' for c in match.group(2))\n",
    "\n",
    "def At_Best_Stopper_In_Suit(regex,match): # at best stop in !C\n",
    "    return f\"At_Best_Stopper_{match.group(1)}==True\"\n",
    "\n",
    "def At_Best_Partial_Stopper_In_Suit(regex,match): # at best partial stop in !C\n",
    "    return f\"At_Best_Partial_Stopper_{match.group(1)}==True\"\n",
    "\n",
    "def Biddable_Suit(regex,match): # biddable !C\n",
    "    return f\"Biddable_{match.group(1)}==True\"\n",
    "\n",
    "def Forcing_One_Round(regex,match): # forcing (one round)\n",
    "    return None # f\"Forcing_One_Round==True\"\n",
    "\n",
    "def Forcing_To(regex,match): # forcing to 3N\n",
    "    return None # f\"Forcing_To_{match.group(1)}==True\"\n",
    "\n",
    "def Likely_Stopper_In_Suit(regex,match): # likely stop in !C\n",
    "    return f\"Likely_Stopper_{match.group(1)}==True\"\n",
    "\n",
    "def No_Cards_In_Suit(regex,match): # no !C\n",
    "    return f\"SL_{match.group(1)} == 0\"\n",
    "\n",
    "def Cards_Not_In_Suit(regex,match): # no !CAKQ\n",
    "    return ' & '.join('C_'+match.group(1)+c+'==False' for c in match.group(2)) # negated\n",
    "\n",
    "def Opponents_Cannot_Play_Undoubled_Below_Bid(regex,match): # opponents cannot play undoubled below 2N\n",
    "    return f\"Opponents_Cannot_Play_Undoubled_Below_{match.group(1)}==True\"\n",
    "\n",
    "def Partial_Stopper_In_Suit(regex,match): # partial stop in !C\n",
    "    return f\"Partial_Stopper_{match.group(1)}==True\"\n",
    "\n",
    "def Rebiddable_Suit(regex,match): # twice rebiddable !C\n",
    "    return f\"Rebiddable_{match.group(1)}==True\"\n",
    "\n",
    "def Solid_SL_Suit(regex,match): # sold suit of n cards\n",
    "    return f\"Solid_{match.group(2)}==True & SL_{match.group(2)} >= {match.group(1)}\" # todo: == or >=?\n",
    "\n",
    "def Stopper_In_Suit(regex,match): # stop in !C\n",
    "    return f\"Stopper_{match.group(1)}==True\"\n",
    "\n",
    "def Strong_Rebiddable_Suit(regex,match): # strong rebiddable !C\n",
    "    return f\"Strong_Rebiddable_{match.group(1)}==True\"\n",
    "\n",
    "def Twice_Rebiddable_Suit(regex,match): # twice rebiddable !C\n",
    "    return f\"Twice_Rebiddable_{match.group(1)}==True\"\n",
    "\n",
    "def Two_Stoppers_In_Suit(regex,match): # two stops in !C\n",
    "    return f\"Two_Stoppers_{match.group(1)}==True\"\n",
    "\n",
    "# careful: regex must use longest form of sub_expr. e.g. HCP -> HCPs\n",
    "expr_regex = [\n",
    "    (r'^(\\d+)$',HCP_Exact), # 10 todo: HCP or total points?\n",
    "    (r'^(\\d+)\\-$',HCP_At_Most), # 10- todo: HCP or total points?\n",
    "    (r'^(\\d+)\\+$',HCP_At_Least), # 10+ todo: HCP or total points?\n",
    "    (r'^(\\d+)\\-(\\d+)$',HCP_Between), # 10-12 todo: HCP or total points?\n",
    "    (r'^(\\d+) \\!([CDHS])$',Suit_Length_Exact), # 4 !C\n",
    "    (r'^(\\d+)\\- \\!([CDHS])$',Suit_Length_At_Most), # 4- !C\n",
    "    (r'^(\\d+)\\-card \\!([CDHS])$',Suit_Length_Exact), # 4-card !C should be 4 !C\n",
    "    (r'^(\\d+)\\+ \\!([CDHS])$',Suit_Length_At_Least), # 4+ !C\n",
    "    (r'^(\\d+)\\-(\\d+) \\!([CDHS])$',Suit_Length_Between), # 2-3 !C\n",
    "    (r'^(\\d+) HCPs$',HCP_Exact), # 10 HCP\n",
    "    (r'^(\\d+)\\- HCPs$',HCP_At_Most), # 10- HCP\n",
    "    (r'^(\\d+)\\+ HCPs$',HCP_At_Least), # 10+ HCP\n",
    "    (r'^(\\d+)\\-(\\d+) HCPs$',HCP_Between), # 10-12 HCP\n",
    "    (r'^(\\d+) (?:to|total)(?: points)?$',Total_Points_Exact), # 10 total points\n",
    "    (r'^(\\d+)\\- (?:to|total)(?: points)?$',Total_Points_At_Most), # 10- total points\n",
    "    (r'^(\\d+)\\+ (?:to|total)(?: points)?$',Total_Points_At_Least), # 10+ total points\n",
    "    (r'^(\\d+)-(\\d+) (?:to|total)(?: points)?$',Total_Points_Between), # 10-12 total points\n",
    "    (r'^([AKQ]+)\\+ in \\!([CDHS])$',Cards_In_Suit), # Q+ in !C\n",
    "    (r'^\\!([CDHS])([AKQ]+)$',Suit_Has_Cards), # !CAK\n",
    "    (r'^at best stop in \\!([CDHS])$',At_Best_Stopper_In_Suit), # partial stop in !C\n",
    "    (r'^at best partial stop in \\!([CDHS])$',At_Best_Partial_Stopper_In_Suit), # partial stop in !C\n",
    "    (r'^biddable \\!([CDHS])$',Biddable_Suit), # biddable !C\n",
    "    (r'^forcing$',Forcing_One_Round), # forcing (one round)\n",
    "    (r'^forcing to (\\d[CDHSN])$',Forcing_To), # forcing to 3N\n",
    "    (r'^likely stop in \\!([CDHS])$',Likely_Stopper_In_Suit), # likely stop in !C\n",
    "    (r'^no \\!([CDHS])$',No_Cards_In_Suit), # no !C\n",
    "    (r'^no \\!([CDHS])([AKQ]+)$',Cards_Not_In_Suit), # no !CAKQ\n",
    "    (r'^opponents cannot play undoubled below (\\d[CDHSN])$',Opponents_Cannot_Play_Undoubled_Below_Bid), # opponents cannot play undoubled below 2!N\n",
    "    (r'^partial stop(?: in)? \\!([CDHS])$',Partial_Stopper_In_Suit), # partial stop in !C\n",
    "    (r'^rebiddable \\!([CDHS])$',Rebiddable_Suit), # twice rebiddable !C\n",
    "    # 'No stoppers to bid' is superfluous. It's always accompanied by explict 'at best partial stop in' and 'forcing'.\n",
    "    (r'^solid (\\d)\\-card \\!([CDHS])$',Solid_SL_Suit), # sold suit of n cards\n",
    "    (r'^stop in \\!([CDHS])$',Stopper_In_Suit), # stop in !C\n",
    "    (r'^strong rebiddable \\!([CDHS])$',Strong_Rebiddable_Suit), # strong rebiddable !C\n",
    "    (r'^twice rebiddable \\!([CDHS])$',Twice_Rebiddable_Suit), # twice rebiddable !C\n",
    "    (r'^two stops in !([CDHS])$',Two_Stoppers_In_Suit), # two stops in !C\n",
    "]\n",
    "\n",
    "expr_regex_matches = defaultdict(list)\n",
    "unknown_sub_expr = defaultdict(list)\n",
    "for i,(sub_expr_parts,an) in enumerate(sub_expr_parts_list):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i}/{len(sub_expr_parts_list)} {sub_expr_parts=} {an=}\")\n",
    "    if sub_expr_parts == []:\n",
    "        print('  Skipping empty list')\n",
    "        continue\n",
    "    sub_expr = ' '.join([truncation_to_keywords[se] if se in truncation_to_keywords else se for se in sub_expr_parts])\n",
    "    #print(f\"  {sub_expr=}\")\n",
    "    matches = []\n",
    "    #time.sleep(.00001)\n",
    "    for regex,f in expr_regex:\n",
    "        #print(sub_expr,regex)\n",
    "        mg = re.match(regex,sub_expr)\n",
    "        if mg is not None:\n",
    "            #print(f\"{regex=} {mg=}\")\n",
    "            eval_expr = f(regex,mg)\n",
    "            #print(eval_expr)\n",
    "            if eval_expr is None: # todo: forcing ... not implemented.\n",
    "                print('Unimplemented an:',an,' sub_expr:',sub_expr)\n",
    "                continue\n",
    "            matches.append((regex,mg.groups(1),eval_expr))\n",
    "            #assert False, eval_expr\n",
    "    if len(matches) == 0:\n",
    "        print('Unmatched matches: an:',an,' matches:',matches)\n",
    "        if an in obsolete_announcements:\n",
    "            obs_an, obs_lin_file, obs_keeper_an, obs_keeper_lin_file = obsolete_announcements[an]\n",
    "            if an in corrected_announcements:\n",
    "                print('Announcement has been corrected:',obs_keeper_an,' file:',obs_keeper_lin_file)\n",
    "        unknown_sub_expr[sub_expr].append(an)\n",
    "        continue\n",
    "    assert len(matches) == 1, ['Ambiguous sub_expr:',an,matches]\n",
    "    expr_regex_matches[an].append(matches)\n",
    "\n",
    "expr_regex_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124041f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:31:20.718595Z",
     "start_time": "2023-09-18T22:30:20.581960Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 3m\n",
    "# show a list of unknown announcement sub-expressions errors\n",
    "print('Unknown sub-expressions:',len(unknown_sub_expr))\n",
    "rows = []\n",
    "for k,v in sorted(unknown_sub_expr.items()):\n",
    "    print(f\"\\n'{k}' occurences={len(v)}\")\n",
    "    for an in v:\n",
    "        print(f\"{an=}\")\n",
    "        for prev_bids,bid,lin_file in announcements[an]:\n",
    "            print(f\"    {prev_bids=} {bid=} '{an=} {lin_file}'\")\n",
    "            rows.append((prev_bids,bid,an,k,lin_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd6dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:31:31.133175Z",
     "start_time": "2023-09-18T22:31:20.718595Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 10s\n",
    "# create python file containing a table of all bidding sequences, 2,500,000.\n",
    "#bbo_bidding_sequences_table = [\n",
    "#    (0, (), 'p', '', 'not implemented'),\n",
    "#    (1, 'p', 'p', '', 'not implemented'),\n",
    "#    (2, ('p', 'p'), '1D', 'Minor suit opening -- 3+ !D; 11-21 HCP; 12-22 total points', 'not implemented'),\n",
    "# ...\n",
    "# ]\n",
    "\n",
    "with open('bbo_bidding_sequences_table.py', 'w', encoding='utf8') as f:\n",
    "    date_time_str = datetime.datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    f.write('\\n')\n",
    "    f.write(\"'''\\n\")\n",
    "    f.write(f\"# This python file was automatically created on {date_time_str}.\\n\")\n",
    "    f.write('\\n')\n",
    "    f.write('Glossary. Unless explicitly stated, criteria applies to bidders hand.\\n')\n",
    "    f.write('HCP = High Card Points\\n')\n",
    "    f.write('QT = Quick Tricks\\n')\n",
    "    f.write('SL_[NESW] = Suit Length e.g SL_S is suit length in spades\\n')\n",
    "    f.write('Balanced = Balanced distribution\\n')\n",
    "    f.write('Vul = Vulnerability e.g. None, Us, Them, Both\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Shortcut Notations\\n')\n",
    "    f.write('{suit} is a shortcut notation for the bid suit. e.g For a bid of 1S: HCP_{suit} will become HCP_S\\n')\n",
    "    f.write('HCP_{suit} = HCP in bid suit\\n')\n",
    "    f.write('QT_{suit} = QT in bid suit\\n')\n",
    "    f.write('SL_{suit} = SL in bid suit\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Arithmetic Operators. Same as using a calculator.\\n')\n",
    "    f.write('+ is addition\\n')\n",
    "    f.write('- is subtraction\\n')\n",
    "    f.write('* is multiplication\\n')\n",
    "    f.write('/ is division\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Boolean Operators')\n",
    "    f.write('Due to Pandas restrictions, boolean values must be written using a comparison operator. e.g. Balanced==True\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('Logical Operators\\n')\n",
    "    f.write('== is compares equal\\n')\n",
    "    f.write('!= is compares not equal\\n')\n",
    "    f.write('other variations are <=, <, >, >=\\n')\n",
    "    f.write('& = logical and e.g. result is true if both left and right are true\\n')\n",
    "    f.write('| = logical or e.g. result is true if either left or right is true\\n')\n",
    "    f.write('^ = logical exclusive or (rare) e.g. result is true if either both left and right are same (both true or both false)\\n')\n",
    "    f.write('() groups expressions togther e.g for 1NT-2C: HCP >= 8 (SL_H >= 4 | SL_S >= 4)\\n')\n",
    "    f.write(\"'''\\n\")\n",
    "    f.write('\\n')\n",
    "    f.write('# (Id, previous bids, candidate bid):(comment, eval_expr)\\n')\n",
    "    f.write('bbo_bidding_sequences_table = [\\n')\n",
    "    for i,(k,v) in enumerate(corrected_bidding_table.items()):\n",
    "        # previous bids, candidate bid, announcement, pandas eval expr\n",
    "        eval_expr = ' & '.join(e[2] for m in expr_regex_matches[v[0]] for e in m if e[2] is not None)\n",
    "        announcement = v[0].replace(\"'\",\"\\\\'\")\n",
    "        f.write(f\"    ({i},{k[0]},{k[1]},'{announcement}','{eval_expr}'),\\n\")\n",
    "    f.write(']\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d703e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:31:31.584911Z",
     "start_time": "2023-09-18T22:31:31.133175Z"
    }
   },
   "outputs": [],
   "source": [
    "error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3132a9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:31:33.793658Z",
     "start_time": "2023-09-18T22:31:31.585913Z"
    }
   },
   "outputs": [],
   "source": [
    "bid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b0653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:31:35.756733Z",
     "start_time": "2023-09-18T22:31:33.793658Z"
    }
   },
   "outputs": [],
   "source": [
    "final_contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852bf06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:33:11.422495Z",
     "start_time": "2023-09-18T22:31:35.757735Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes 4m for bidding sequences/s\n",
    "# if attribute error: pip install xlsxwriter\n",
    "\n",
    "# error: 'Worksheet' object has no attribute 'set_column' due to missing: pip install xlsxwriter\n",
    "\n",
    "# todo: expr_regex sheet\n",
    "\n",
    "def Autosize_Column_Widths(writer, sheet_name, df, max_width=50):\n",
    "    \n",
    "    # Auto-adjust columns' width\n",
    "    for column in df:\n",
    "        column_width = max(df[column].astype(str).map(len).max(), len(column))\n",
    "        column_width = min(column_width, max_width)\n",
    "        col_idx = df.columns.get_loc(column)\n",
    "        writer.sheets[sheet_name].set_column(col_idx, col_idx, column_width)\n",
    "\n",
    "# output Excel file. Excel is limited to 1M rows total of all sheets.\n",
    "with pd.ExcelWriter('BBO_Bidding_Sequences.xlsx') as writer:\n",
    "\n",
    "    # lin files contain multiple bids so there may be 25% more bids than lin files.\n",
    "    sheet_name = 'Bidding Sequences (Sampled)'\n",
    "    cols = defaultdict(list)\n",
    "    for i,(k,v) in enumerate(corrected_bidding_table.items()):\n",
    "        criterias = ([None]*20)[:len(expr_regex_matches[v[0]])] if corrected_announcement_parts[v[0]][2] is None else corrected_announcement_parts[v[0]][2]\n",
    "        cols['Id'].append(i)\n",
    "        cols['Previous_Bids'].append(k[0])\n",
    "        cols['Candidate_Bid'].append(k[1])\n",
    "        cols['Announcement'].append(v[0])\n",
    "        cols['Comment'].append(corrected_announcement_parts[v[0]][0])\n",
    "        cols['Criteria'].append('')\n",
    "        cols['RegEx'].append('')\n",
    "        cols['Match_Values'].append('')\n",
    "        eval_expr = ' & '.join('' if e[2] is None else e[2] for m in expr_regex_matches[v[0]] for e in m)\n",
    "        #print(expr_regex_matches[v[0]])\n",
    "        #print(eval_expr)\n",
    "        #continue\n",
    "        cols['Pandas_Eval_Expr'].append(eval_expr)\n",
    "        for i,(criteria,matches) in enumerate(zip(criterias,expr_regex_matches[v[0]])):\n",
    "            # Clear out cells when columns are redundant, 2nd+ rows, for better readability.\n",
    "            cols['Id'].append('')\n",
    "            cols['Previous_Bids'].append('')\n",
    "            cols['Candidate_Bid'].append('')\n",
    "            cols['Announcement'].append('')\n",
    "            cols['Comment'].append('')\n",
    "            cols['Criteria'].append(criteria)\n",
    "            cols['RegEx'].append(matches[0][0])\n",
    "            cols['Match_Values'].append(matches[0][1])\n",
    "            cols['Pandas_Eval_Expr'].append(matches[0][2])\n",
    "\n",
    "    max_rows = 100000\n",
    "    df = pd.DataFrame(cols).sample(max_rows).sort_index()\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    sheet_name = 'Lin Files (Sampled)' # sample 100000 rows\n",
    "    df = pd.DataFrame(\n",
    "        [[k,*v] for k,v in files_processed.items()],\n",
    "        columns=['lin_file', 'error', 'username', 'board', 'dealer', 'vul', 'hands', 'bids', 'cards']).sample(100000)\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    sheet_name = 'Announcement Errors (Sampled)' # sample 100000 rows\n",
    "    df = pd.DataFrame([[', '.join(prev_bids),bid,an,k,files_processed[lin_file][1],lin_file.name] for prev_bids,bid,an,k,lin_file in rows],columns=['Previous Bids','Candidate Bid','Announcement','Invalid Part','Username','Source file']).sample(max_rows).sort_index()\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    sheet_name = 'Obsolete Announcements List'\n",
    "    df = pd.DataFrame.from_dict(obsolete_announcements,orient='index',columns=['Obsolete Announcement','Obsolete Lin File','Corrected Announcement','Corrected Lin File'])\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    sheet_name = 'Expression Vocabulary'\n",
    "    df = pd.DataFrame(expr_keywords,columns=[sheet_name])\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    sheet_name = 'Usernames'\n",
    "    df = pd.DataFrame({'Username':[v[1] for k,v in files_processed.items()]}).value_counts().reset_index() # reset allows column renaming\n",
    "    df.columns = ['Username','Count']\n",
    "    display(df)\n",
    "    df.to_excel(writer, sheet_name, index=False, na_rep='NaN',freeze_panes=(1,0))\n",
    "    Autosize_Column_Widths(writer,sheet_name,df)\n",
    "\n",
    "    #writer.close() # saves and closes # not needed within with statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12502704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:33:11.438649Z",
     "start_time": "2023-09-18T22:33:11.422495Z"
    }
   },
   "outputs": [],
   "source": [
    "l = df['Username'].tolist()\n",
    "#for un in l:\n",
    "print(\"['\"+\"','\".join(ll for ll in l if not ll.startswith(\"~~\"))+\"']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a876a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T22:33:11.469109Z",
     "start_time": "2023-09-18T22:33:11.439652Z"
    }
   },
   "outputs": [],
   "source": [
    "# output usernames to file. copy to bbo-downloader to update with latest collection of usernames.\n",
    "with open('bbo_usernames.txt','w',encoding='utf8') as f:\n",
    "    for un in df['Username'].tolist(): # output in count order as opposed to alphabetical.\n",
    "        if un.startswith('~~'):\n",
    "            continue\n",
    "        f.write(un+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573ea66",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
